_target_: src.models.graph_bert_model_for_text.GraphBertNodeClassificationModuleForText
config:
  _target_: src.models.modules.graph_bert_layers.GraphBertConfig
  residual_type: "none"
  x_size: 1000
  y_size: 1
  k: 5
  max_wl_role_index: 100
  max_hop_dis_index: 100
  max_inti_pos_index: 100
  hidden_size: 32
  num_hidden_layers: 1
  num_attention_heads: 1
  intermediate_size: 32
  hidden_act: "gelu"
  hidden_dropout_prob: 0.5
  attention_probs_dropout_prob: 0.3
  initializer_range: 0.02
  layer_norm_eps: 1e-12
  is_decoder: False

train_size: 2326
batch_size: 32
max_epochs: 50
lr: 0.00005 # 5e-5
warmup_epoch: 5
eps: 0.00000001 # 1e-8
weight_decay: 0.01
