_target_: src.models.multi_modal_with_bert_model.MultiModalWithBertModule
amino_vocab_size: 29
node_dim: 128
num_gnn_layers: 2
pretrained_path: dmis-lab/biobert-v1.1
train_size:
batch_size: 32
max_epochs: 20
lr: 0.00005 # 5e-5
warmup_epoch: 5
eps: 0.00000001 # 1e-8
weight_decay: 0.01
