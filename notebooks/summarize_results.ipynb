{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_RES_ROOT = Path(\"../data/multi_modal_ppi_results/single_run\")\n",
    "CV_RES_ROOT = Path(\"../data/multi_modal_ppi_results/cross_validation\")\n",
    "SINGLE_HPRD_PATH = SINGLE_RES_ROOT / \"hprd_run.csv\"\n",
    "SINGLE_BIOINFER_PATH = SINGLE_RES_ROOT / \"bioinfer_run.csv\"\n",
    "CV_HPRD_PATH = CV_RES_ROOT / \"hprd_run.csv\"\n",
    "CV_BIOINFER_PATH = CV_RES_ROOT / \"bioinfer_run.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_hprd_df = pd.read_csv(SINGLE_HPRD_PATH, index_col=\"Name\")\n",
    "single_bioinfer_df = pd.read_csv(SINGLE_BIOINFER_PATH, index_col=\"Name\")\n",
    "cv_hprd_df = pd.read_csv(CV_HPRD_PATH, index_col=\"Name\")\n",
    "cv_bioinfer_df = pd.read_csv(CV_BIOINFER_PATH, index_col=\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODULE_CHOICES = [\n",
    "    \"TextModule\",\n",
    "    \"TextAndGraphModule\",\n",
    "    \"TextAndNumModule\",\n",
    "    \"TextAndGraphAndNumModule\",\n",
    "    \"GraphModule\",\n",
    "    \"GraphAndNumModule\",\n",
    "    \"NumModule\",\n",
    "]\n",
    "\n",
    "METRICS_CHOICES = [\n",
    "    (\"val/f1_mean\", \"Valid F1 score\"),\n",
    "    (\"test/prec_mean\", \"Test F1 score\"),\n",
    "    (\"test/rec_mean\", \"Test F1 score\"),\n",
    "    (\"test/f1_mean\", \"Test F1 score\"),\n",
    "    (\"test/auroc_mean\", \"AUROC\")\n",
    "]\n",
    "\n",
    "PIVOT_METRIC = METRICS_CHOICES[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(df: pd.DataFrame, MODULE_CHOICES=MODULE_CHOICES, PIVOT_METRIC=PIVOT_METRIC):\n",
    "    for module in MODULE_CHOICES:\n",
    "        print(f\"Module: {module}\")\n",
    "        tmp_df = df.query(f\"index.str.contains('{module}')\").query(f\"index.str.startswith('{module[0]}')\")\n",
    "        max_idx = tmp_df[PIVOT_METRIC].idxmax()\n",
    "        max_row = tmp_df.loc[max_idx]\n",
    "        for _metric in METRICS_CHOICES:\n",
    "            print(f\"    {_metric[0] + ':':<20}{100*max_row[{_metric[0]}][_metric[0]]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single run: Result for hprd\n",
      "Module: TextModule\n",
      "    val/f1_mean:        52.49\n",
      "    test/prec_mean:     93.33\n",
      "    test/rec_mean:      70.00\n",
      "    test/f1_mean:       80.00\n",
      "    test/auroc_mean:    96.25\n",
      "Module: TextAndGraphModule\n",
      "    val/f1_mean:        60.19\n",
      "    test/prec_mean:     87.50\n",
      "    test/rec_mean:      70.00\n",
      "    test/f1_mean:       77.78\n",
      "    test/auroc_mean:    98.37\n",
      "Module: TextAndNumModule\n",
      "    val/f1_mean:        50.64\n",
      "    test/prec_mean:     78.95\n",
      "    test/rec_mean:      75.00\n",
      "    test/f1_mean:       76.92\n",
      "    test/auroc_mean:    97.27\n",
      "Module: TextAndGraphAndNumModule\n",
      "    val/f1_mean:        62.50\n",
      "    test/prec_mean:     82.35\n",
      "    test/rec_mean:      70.00\n",
      "    test/f1_mean:       75.68\n",
      "    test/auroc_mean:    97.10\n",
      "Module: GraphModule\n",
      "    val/f1_mean:        3.03\n",
      "    test/prec_mean:     0.00\n",
      "    test/rec_mean:      0.00\n",
      "    test/f1_mean:       0.00\n",
      "    test/auroc_mean:    47.70\n",
      "Module: GraphAndNumModule\n",
      "    val/f1_mean:        13.07\n",
      "    test/prec_mean:     0.00\n",
      "    test/rec_mean:      0.00\n",
      "    test/f1_mean:       0.00\n",
      "    test/auroc_mean:    51.28\n",
      "Module: NumModule\n",
      "    val/f1_mean:        9.60\n",
      "    test/prec_mean:     9.68\n",
      "    test/rec_mean:      30.00\n",
      "    test/f1_mean:       14.63\n",
      "    test/auroc_mean:    50.05\n",
      "------------------------------\n",
      "Single run: Result for bioinfer\n",
      "Module: TextModule\n",
      "    val/f1_mean:        75.71\n",
      "    test/prec_mean:     81.20\n",
      "    test/rec_mean:      86.38\n",
      "    test/f1_mean:       83.71\n",
      "    test/auroc_mean:    95.49\n",
      "Module: TextAndGraphModule\n",
      "    val/f1_mean:        75.27\n",
      "    test/prec_mean:     84.39\n",
      "    test/rec_mean:      85.11\n",
      "    test/f1_mean:       84.75\n",
      "    test/auroc_mean:    95.40\n",
      "Module: TextAndNumModule\n",
      "    val/f1_mean:        76.30\n",
      "    test/prec_mean:     80.54\n",
      "    test/rec_mean:      88.09\n",
      "    test/f1_mean:       84.15\n",
      "    test/auroc_mean:    96.60\n",
      "Module: TextAndGraphAndNumModule\n",
      "    val/f1_mean:        76.85\n",
      "    test/prec_mean:     83.81\n",
      "    test/rec_mean:      88.09\n",
      "    test/f1_mean:       85.89\n",
      "    test/auroc_mean:    97.49\n",
      "Module: GraphModule\n",
      "    val/f1_mean:        7.03\n",
      "    test/prec_mean:     0.00\n",
      "    test/rec_mean:      0.00\n",
      "    test/f1_mean:       0.00\n",
      "    test/auroc_mean:    45.77\n",
      "Module: GraphAndNumModule\n",
      "    val/f1_mean:        25.58\n",
      "    test/prec_mean:     19.27\n",
      "    test/rec_mean:      29.36\n",
      "    test/f1_mean:       23.27\n",
      "    test/auroc_mean:    48.57\n",
      "Module: NumModule\n",
      "    val/f1_mean:        19.29\n",
      "    test/prec_mean:     13.13\n",
      "    test/rec_mean:      16.60\n",
      "    test/f1_mean:       14.66\n",
      "    test/auroc_mean:    48.61\n"
     ]
    }
   ],
   "source": [
    "print(\"Single run: Result for hprd\")\n",
    "summarize_results(single_hprd_df)\n",
    "print(\"-\"*30)\n",
    "print(\"Single run: Result for bioinfer\")\n",
    "summarize_results(single_bioinfer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV run: Result for hprd\n",
      "Module: TextModule\n",
      "    val/f1_mean:        53.59\n",
      "    test/prec_mean:     78.61\n",
      "    test/rec_mean:      72.57\n",
      "    test/f1_mean:       73.34\n",
      "    test/auroc_mean:    94.55\n",
      "Module: TextAndGraphModule\n",
      "    val/f1_mean:        52.08\n",
      "    test/prec_mean:     87.01\n",
      "    test/rec_mean:      74.39\n",
      "    test/f1_mean:       78.21\n",
      "    test/auroc_mean:    95.34\n",
      "Module: TextAndNumModule\n",
      "    val/f1_mean:        56.61\n",
      "    test/prec_mean:     75.06\n",
      "    test/rec_mean:      72.18\n",
      "    test/f1_mean:       71.98\n",
      "    test/auroc_mean:    92.61\n",
      "Module: TextAndGraphAndNumModule\n",
      "    val/f1_mean:        54.57\n",
      "    test/prec_mean:     83.84\n",
      "    test/rec_mean:      71.03\n",
      "    test/f1_mean:       75.21\n",
      "    test/auroc_mean:    94.86\n",
      "Module: GraphModule\n",
      "    val/f1_mean:        14.02\n",
      "    test/prec_mean:     2.57\n",
      "    test/rec_mean:      27.13\n",
      "    test/f1_mean:       4.68\n",
      "    test/auroc_mean:    51.38\n",
      "Module: GraphAndNumModule\n",
      "    val/f1_mean:        18.17\n",
      "    test/prec_mean:     4.00\n",
      "    test/rec_mean:      30.43\n",
      "    test/f1_mean:       7.06\n",
      "    test/auroc_mean:    48.09\n",
      "Module: NumModule\n",
      "    val/f1_mean:        13.20\n",
      "    test/prec_mean:     6.67\n",
      "    test/rec_mean:      43.28\n",
      "    test/f1_mean:       10.42\n",
      "    test/auroc_mean:    53.21\n",
      "------------------------------\n",
      "CV run: Result for bioinfer\n",
      "Module: TextModule\n",
      "    val/f1_mean:        75.66\n",
      "    test/prec_mean:     85.27\n",
      "    test/rec_mean:      84.69\n",
      "    test/f1_mean:       84.88\n",
      "    test/auroc_mean:    96.79\n",
      "Module: TextAndGraphModule\n",
      "    val/f1_mean:        74.92\n",
      "    test/prec_mean:     87.07\n",
      "    test/rec_mean:      83.28\n",
      "    test/f1_mean:       85.05\n",
      "    test/auroc_mean:    95.63\n",
      "Module: TextAndNumModule\n",
      "    val/f1_mean:        76.51\n",
      "    test/prec_mean:     87.12\n",
      "    test/rec_mean:      83.10\n",
      "    test/f1_mean:       85.05\n",
      "    test/auroc_mean:    96.16\n",
      "Module: TextAndGraphAndNumModule\n",
      "    val/f1_mean:        76.48\n",
      "    test/prec_mean:     87.07\n",
      "    test/rec_mean:      84.66\n",
      "    test/f1_mean:       85.80\n",
      "    test/auroc_mean:    96.79\n",
      "Module: GraphModule\n",
      "    val/f1_mean:        4.47\n",
      "    test/prec_mean:     5.71\n",
      "    test/rec_mean:      1.26\n",
      "    test/f1_mean:       2.07\n",
      "    test/auroc_mean:    51.06\n",
      "Module: GraphAndNumModule\n",
      "    val/f1_mean:        22.37\n",
      "    test/prec_mean:     16.43\n",
      "    test/rec_mean:      25.61\n",
      "    test/f1_mean:       19.94\n",
      "    test/auroc_mean:    49.84\n",
      "Module: NumModule\n",
      "    val/f1_mean:        18.94\n",
      "    test/prec_mean:     16.79\n",
      "    test/rec_mean:      17.43\n",
      "    test/f1_mean:       16.99\n",
      "    test/auroc_mean:    50.94\n"
     ]
    }
   ],
   "source": [
    "print(\"CV run: Result for hprd\")\n",
    "summarize_results(cv_hprd_df)\n",
    "print(\"-\"*30)\n",
    "print(\"CV run: Result for bioinfer\")\n",
    "summarize_results(cv_bioinfer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5141fc10e8a935e138f3e243e5417da10412e5ff0f60bc491789adff2bddecfb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('lightning-hydra-template-aIZGJKDg-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
